---
title: "R_3"
author: "Ainhoa"
date: "2024-05-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
packages <- c('tidyverse','rpart','rpart.plot','gtools','Rmisc','scales','viridis','caret','AMR','randomForest','fastDummies','rattle','xgboost','ggpubr','reshape2','mlbench')

if(sum(as.numeric(!packages %in% installed.packages())) != 0){
  instalador <- packages[!packages %in% installed.packages()]
  for(i in 1:length(instalador)) {
    install.packages(instalador, dependencies = T)
    break()}
  sapply(packages, require, character = T) 
} else {
  sapply(packages, require, character = T) }
library(readxl)
library(ranger)
library(tidymodels)
library(parallel)
library(doParallel)
```

# Regression 
## Preparing the data
```{r}
df <- read_excel("df_definitivo-2.xlsx", sheet = "Copia de datos")
rownames(df) = df$id
df$Afectacion_ganglionar = as.numeric(df$Afectacion_ganglionar)
df$Afectacion_metastasica = as.numeric(df$Afectacion_metastasica)
df$Tamaño_tumor = as.numeric(df$Tamaño_tumor)
df$Grado_tox = as.numeric(df$Grado_tox)
df$SII_pre = log(df$SII_pre)
df$SII_1C = log(df$SII_1C)
df$SII_2C = log(df$SII_2C)
df$SII_1eval = log(df$SII_1eval)

variables_inutiles = c("Anciano", "Peso", "Talla", "SG", "SG_cens", "SLP", "SLP_cens", "Tipo_tox", "NLR2C_corte4o5")

df2 = select(df, -all_of(variables_inutiles))
```

## SELECCIÓN DE VARIABLES PARA MEJOR RESPUESTA
```{r SELECCIÓN DE VARIABLES PARA MEJOR RESPUESTA}
X2 = df2[,2:67]
X2$mejor_resp_num_ok <- df2$mejor_resp_num_ok
```
## Modelo sin ajuste de parametros-MEJOR RESPUESTA-
```{r}
# Creación y entrenamiento del modelo
# ==============================================================================
set.seed(123)
modelo2  <- ranger(
            formula   = mejor_resp_num_ok ~ .,
            data      = X2,
            num.trees = 10,
            seed      = 123
           )

print(modelo2)
```
```{r}
predict(modelo2, X2) %>% head
```
## Ealuating the model
```{r}
# Training data
p_train2 <- predict(modelo2, X2)

# Evaluation data frame (Training)
eval_train2 <- data.frame(obs=X2$mejor_resp_num_ok,
                         pred=p_train2)
head(eval_train2)

predicciones2 <- p_train2$predictions
```

```{r}
# Using the evaluation function
# Evaluation function
evaluate <- function(pred, obs) {
  mse <- mean((pred - obs)^2)
  rmse_ <- sqrt(mse)
  mae <- mean(abs(pred - obs))
  r_squared <- 1 - (sum((obs - pred)^2) / sum((obs - mean(obs))^2))

  cat("MSE:", mse, "\n")
  cat("RMSE:", rmse_, "\n")
  cat("MAE:", mae, "\n")
  cat("R-squared:", r_squared, "\n")
}

evaluate(predicciones2, X2$mejor_resp_num_ok)
```

### Grid-search con LOO
```{r}
# DEFINICIÓN DEL MODELO Y DE LOS HIPERPARÁMETROS A OPTIMIZAR
# ==============================================================================
modelo <- rand_forest(
             mode  = "regression",
             mtry  = tune(),
             trees = tune()
          ) %>%
          set_engine(
            engine     = "ranger",
            max.depth  = tune(),
            importance = "none",
            seed       = 123
          )

# DEFINICIÓN DEL PREPROCESADO
# ==============================================================================
# En este caso no hay preprocesado, por lo que el transformer solo contiene
# la definición de la fórmula y los datos de entrenamiento.
transformer <- recipe(
                  formula = mejor_resp_num_ok ~ .,
                  data    =  X2
               )

# DEFINICIÓN DE LA ESTRATEGIA DE VALIDACIÓN Y CREACIÓN DE PARTICIONES
# ==============================================================================
set.seed(1234)
cv_folds <- vfold_cv(
              data    = X2,
              v       = nrow(X2),
              repeats = 1,
              strata  = mejor_resp_num_ok
            )

# WORKFLOW
# ==============================================================================
workflow_modelado <- workflow() %>%
                     add_recipe(transformer) %>%
                     add_model(modelo)
                     

# GRID DE HIPERPARÁMETROS
# ==============================================================================
hiperpar_grid <- expand_grid(
                  'trees'     = c(50, 100, 500, 1000, 5000),
                  'mtry'      = c(3, 5, 7, ncol(X2)-1),
                  'max.depth' = c(1, 3, 10, 20)
                 )

# EJECUCIÓN DE LA OPTIMIZACIÓN DE HIPERPARÁMETROS
# ==============================================================================

cl2 <- makePSOCKcluster(parallel::detectCores() - 1)
registerDoParallel(cl2)

grid_fit <- tune_grid(
              object    = workflow_modelado,
              resamples = cv_folds,
              metrics   = metric_set(rmse),
              grid      = hiperpar_grid
            )

stopCluster(cl2)
```

```{r}
# Mejores hiperparámetros por validación cruzada
# ==============================================================================
show_best(grid_fit, metric = "rmse", n = 1)
```

### Entrenar el modelo con los mejores hiperparámetros
```{r}
# ENTRENAMIENTO FINAL
# =============================================================================
mejores_hiperpar <- select_best(grid_fit, metric = "rmse")

modelo_final_fit <- finalize_workflow(
                        x = workflow_modelado,
                        parameters = mejores_hiperpar
                    ) %>%
                    fit(
                      data = X2
                    ) %>%
                    extract_fit_parsnip()
```

```{r}
# Error de train del modelo final
# ==============================================================================
predicciones <- modelo_final_fit %>%
                predict(
                  new_data = X2,
                  type     = "numeric"
                )

predicciones <- predicciones %>% 
                bind_cols(X2 %>% dplyr::select(mejor_resp_num_ok))

rmse_train  <- rmse(
                 data     = predicciones,
                 truth    = mejor_resp_num_ok,
                 estimate = .pred,
                 na_rm    = TRUE
              )
rmse_train
```

##Importancia de predictores

Importancia por pureza de nodos

En los modelos anteriores, el argumento importance se deja por defecto como "none". Esto desactiva el cálculo de importancia de predictores para reducir así el tiempo de entrenamiento. Se entrena de nuevo el modelo, con los mejores hiperparámetros encontrados, pero esta vez indicando importance = "impurity". Los modelos ranger calculan la impureza a partir del índice Gini en problemas de clasificación y con la varianza en regresión.

```{r}
# Entrenamiento modelo
modelo <- rand_forest(
             mode  = "regression"
          ) %>%
          set_engine(
            engine     = "ranger",
            importance = "impurity",
            seed       = 123
          )

modelo <- modelo %>% finalize_model(mejores_hiperpar)
modelo <- modelo %>% fit(mejor_resp_num_ok ~., data = X2)

# Importancia
importancia_pred <- modelo$fit$variable.importance %>%
                    enframe(name = "predictor", value = "importancia")

# Gráfico
ggplot(
  data = importancia_pred,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "predictor", title = "Importancia predictores (pureza de nodos)") +
geom_col() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 5))
```

## Importancia por permutación
Se entrena de nuevo el modelo, con los mejores hiperparámetros encontrados, pero esta vez indicando importance = "permutation".
```{r}
# Entrenamiento modelo
modelo <- rand_forest(
             mode  = "regression"
          ) %>%
          set_engine(
            engine     = "ranger",
            importance = "permutation",
            seed       = 123
          )

modelo <- modelo %>% finalize_model(mejores_hiperpar)
modelo <- modelo %>% fit(mejor_resp_num_ok ~., data = X2)

# Importancia
importancia_pred <- modelo$fit$variable.importance %>%
                    enframe(name = "predictor", value = "importancia")

# Gráfico
ggplot(
  data = importancia_pred,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "predictor", title = "Importancia predictores (permutación)") +
geom_col() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 5))
```
Ambas estrategias identifican Grado_tox, Toxicidad, Linf_1eval, PLR_1C y NLR_1eval,  como los predictores más influyentes, acorde a los datos de entrenamiento.

# Clasificación
```{r}
# Remove all objects from the global environment and the console
rm(list = ls())
cat("\014")
```
## Preparing the data
```{r}
df <- read_excel("df_definitivo-2.xlsx", sheet = "Copia de datos")
rownames(df) = df$id
df$Afectacion_ganglionar = as.numeric(df$Afectacion_ganglionar)
df$Afectacion_metastasica = as.numeric(df$Afectacion_metastasica)
df$Tamaño_tumor = as.numeric(df$Tamaño_tumor)
df$Grado_tox = as.numeric(df$Grado_tox)
df$SII_pre = log(df$SII_pre)
df$SII_1C = log(df$SII_1C)
df$SII_2C = log(df$SII_2C)
df$SII_1eval = log(df$SII_1eval)

variables_inutiles = c("Anciano", "Peso", "Talla", "SG", "SG_cens", "SLP", "SLP_cens", "Tipo_tox", "NLR2C_corte4o5")

df2 = select(df, -all_of(variables_inutiles))
```

## SELECCIÓN DE VARIABLES PARA MEJOR RESPUESTA
```{r SELECCIÓN DE VARIABLES PARA MEJOR RESPUESTA}
X2 = df2[,2:67]
X2$mejor_resp_num_ok <- as.factor(df2$mejor_resp_num_ok)
```

## Mejora de los hiperparámetros
```{r}
# DEFINICIÓN DEL MODELO Y DE LOS HIPERPARÁMETROS A OPTIMIZAR
# ==============================================================================
modelo <- rand_forest(
             mode  = "classification",
             mtry  = tune(),
             trees = tune()
          ) %>%
          set_engine(
            engine     = "ranger",
            max.depth  = tune(),
            importance = "none",
            seed       = 123
          )

# DEFINICIÓN DEL PREPROCESADO
# ==============================================================================
# En este caso no hay preprocesado, por lo que el transformer solo contiene
# la definición de la fórmula y los datos de entrenamiento.
transformer <- recipe(
                  formula = mejor_resp_num_ok ~ .,
                  data    =  X2
               )

# DEFINICIÓN DE LA ESTRATEGIA DE VALIDACIÓN Y CREACIÓN DE PARTICIONES
# ==============================================================================
set.seed(1234)
cv_folds <- vfold_cv(
              data    = X2,
              v       = nrow(X2),
              repeats = 1,
              strata  = mejor_resp_num_ok
            )

# WORKFLOW
# ==============================================================================
workflow_modelado <- workflow() %>%
                     add_recipe(transformer) %>%
                     add_model(modelo)
                     

# GRID DE HIPERPARÁMETROS
# ==============================================================================
hiperpar_grid <- expand_grid(
                  'trees'     = c(50, 100, 500, 1000, 5000),
                  'mtry'      = c(3, 5, 7, ncol(X2)-1),
                  'max.depth' = c(1, 3, 10, 20)
                 )

# EJECUCIÓN DE LA OPTIMIZACIÓN DE HIPERPARÁMETROS
# ==============================================================================
cl <- makePSOCKcluster(parallel::detectCores() - 1)
registerDoParallel(cl)

grid_fit <- tune_grid(
              object    = workflow_modelado,
              resamples = cv_folds,
              metrics   = metric_set(accuracy),
              grid      = hiperpar_grid
            )

stopCluster(cl)
```

```{r}
# Mejores hiperparámetros por validación cruzada
# ==============================================================================
show_best(grid_fit, metric = "accuracy", n = 1)
```

```{r}
# ENTRENAMIENTO FINAL
# =============================================================================
mejores_hiperpar <- select_best(grid_fit, metric = "accuracy")

modelo_final_fit <- finalize_workflow(
                        x = workflow_modelado,
                        parameters = mejores_hiperpar
                    ) %>%
                    fit(
                      data = X2
                    ) %>%
                    pull_workflow_fit()
```

```{r}
# Error de train del modelo final
# ==============================================================================
predicciones <- modelo_final_fit %>%
                predict(new_data = X2)

predicciones <- predicciones %>% 
                bind_cols(X2 %>% dplyr::select(mejor_resp_num_ok))

accuracy_test  <- accuracy(
                     data     = predicciones,
                     truth    = mejor_resp_num_ok,
                     estimate = .pred_class,
                     na_rm    = TRUE
                  )
accuracy_test
```

```{r}
mat_confusion <- predicciones %>%
                 conf_mat(
                   truth     = mejor_resp_num_ok,
                   estimate  = .pred_class
                 )
mat_confusion
```

## Predicción de probabilidades
La mayoría de implementaciones de Random Forest, entre ellas la de ranger, permiten predecir probabilidades cuando se trata de problemas de clasificación. Es importante entender cómo se calculan estos valores para interpretarlos y utilizarlos correctamente.

En el ejemplo anterior, al aplicar predict() se devuelve Si (ventas elevadas) o No (ventas bajas) para cada observación de test. Sin embargo, no se dispone de ningún tipo de información sobre la seguridad con la que el modelo realiza esta asignación. Con predict(type="prob"), en lugar de una clasificación, se obtiene la probabilidad con la que el modelo considera que cada observación puede pertenecer a cada una de las clases.

```{r}
# Predicción de probabilidades
# ==============================================================================
predicciones <- modelo_final_fit %>%
                predict(new_data = X2, type = "prob")
head(predicciones, 4)
```

El resultado de predict(type="prob") es un dataframe con una fila por observación y tantas columnas como clases tenga la variable respuesta. El valor de la primera columna se corresponde con la probabilidad, acorde al modelo, de que la observación pertenezca a la clase No, y así sucesivamente. El valor de probabilidad mostrado para cada predicción se corresponde con la fracción de observaciones de cada clase en los nodos terminales a los que ha llegado la observación predicha en el conjunto de los árboles.

Por defecto, predict() asigna cada nueva observación a la clase con mayor probabilidad (en caso de empate se asigna de forma aleatoria). Sin embargo, este no tiene por qué ser el comportamiento deseado en todos los casos.

##Importancia de predictores

Importancia por pureza de nodos

En los modelos anteriores, el argumento importance se deja por defecto como "none". Esto desactiva el cálculo de importancia de predictores para reducir así el tiempo de entrenamiento. Se entrena de nuevo el modelo, con los mejores hiperparámetros encontrados, pero esta vez indicando importance = "impurity". Los modelos ranger calculan la impureza a partir del índice Gini en problemas de clasificación y con la varianza en regresión.

```{r}
# Entrenamiento modelo
modelo <- rand_forest(
             mode  = "classification"
          ) %>%
          set_engine(
            engine     = "ranger",
            importance = "impurity",
            seed       = 123
          )

modelo <- modelo %>% finalize_model(mejores_hiperpar)
modelo <- modelo %>% fit(mejor_resp_num_ok ~., data = X2)

# Importancia
importancia_pred <- modelo$fit$variable.importance %>%
                    enframe(name = "predictor", value = "importancia")

# Gráfico
ggplot(
  data = importancia_pred,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "predictor", title = "Importancia predictores (pureza de nodos)") +
geom_col() +
scale_fill_viridis_c() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 5))
```
##Importancia por permutación
Se entrena de nuevo el modelo, con los mejores hiperparámetros encontrados, pero esta vez indicando importance = "permutation".
```{r}
# Entrenamiento modelo
modelo <- rand_forest(
             mode  = "classification"
          ) %>%
          set_engine(
            engine     = "ranger",
            importance = "permutation",
            seed       = 123
          )

modelo <- modelo %>% finalize_model(mejores_hiperpar)
modelo <- modelo %>% fit(mejor_resp_num_ok ~., data = X2)

# Importancia
importancia_pred <- modelo$fit$variable.importance %>%
                    enframe(name = "predictor", value = "importancia")

# Gráfico
ggplot(
  data = importancia_pred,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "predictor", title = "Importancia predictores (permutación)") +
geom_col() +
scale_fill_viridis_c() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 5))
```
Ambas estrategias identifican SII_2C, LDH, SII_1C, NLR_1C, y SII_2C,  como los predictores más influyentes, acorde a los datos de entrenamiento.