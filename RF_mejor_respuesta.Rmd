---
title: "RF_mejor_respuesta"
author: "Ainhoa"
date: "2024-05-19"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
packages <- c('tidyverse', 'rpart', 'rpart.plot', 'gtools', 'Rmisc', 'scales', 'viridis', 'caret', 'AMR', 'randomForest', 'fastDummies', 'rattle', 'xgboost', 'ggpubr', 'reshape2', 'mlbench', 'readxl', 'ranger', 'tidymodels', 'parallel', 'doParallel', 'ggpubr')

suppressWarnings({
  if (sum(as.numeric(!packages %in% installed.packages())) != 0) {
    instalador <- packages[!packages %in% installed.packages()]
    for (i in 1:length(instalador)) {
      install.packages(instalador, dependencies = TRUE)
      break
    }
  }
  sapply(packages, require, character.only = TRUE)
})

```

# Regression 
## Preparing the data
```{r}
df <- read_excel("df_definitivo-2.xlsx", sheet = "Copia de datos")
rownames(df) = df$id
df$Afectacion_ganglionar = as.numeric(df$Afectacion_ganglionar)
df$Afectacion_metastasica = as.numeric(df$Afectacion_metastasica)
df$Tamaño_tumor = as.numeric(df$Tamaño_tumor)
df$Grado_tox = as.numeric(df$Grado_tox)
df$SII_pre = log(df$SII_pre)
df$SII_1C = log(df$SII_1C)
df$SII_2C = log(df$SII_2C)
df$SII_1eval = log(df$SII_1eval)

variables_inutiles = c("Anciano", "Peso", "Talla", "SG", "SG_cens", "SLP", "SLP_cens", "Tipo_tox", "NLR2C_corte4o5")

df2 = select(df, -all_of(variables_inutiles))
```

## SELECCIÓN DE VARIABLES PARA MEJOR RESPUESTA
```{r}
X2 = df2[,2:67]
X2$mejor_resp_num_ok <- df2$mejor_resp_num_ok
```

## Modelo sin ajuste de parametros-MEJOR RESPUESTA-
```{r}
# Creación y entrenamiento del modelo
# ==============================================================================
set.seed(123)
modelo2  <- ranger(
            formula   = mejor_resp_num_ok ~ .,
            data      = X2,
            num.trees = 10,
            seed      = 123
           )

print(modelo2)
```
```{r}
predict(modelo2, X2) %>% head
```
## Ealuating the model
```{r}
# Training data
p_train2 <- predict(modelo2, X2)

# Evaluation data frame (Training)
eval_train2 <- data.frame(obs=X2$mejor_resp_num_ok,
                         pred=p_train2)
head(eval_train2)

predicciones2 <- p_train2$predictions
```

```{r}
# Using the evaluation function
# Evaluation function
evaluate <- function(pred, obs) {
  mse <- mean((pred - obs)^2)
  rmse_ <- sqrt(mse)
  mae <- mean(abs(pred - obs))
  r_squared <- 1 - (sum((obs - pred)^2) / sum((obs - mean(obs))^2))

  cat("MSE:", mse, "\n")
  cat("RMSE:", rmse_, "\n")
  cat("MAE:", mae, "\n")
  cat("R-squared:", r_squared, "\n")
}

evaluate(predicciones2, X2$mejor_resp_num_ok)
```

### Grid-search con LOO
```{r}
# DEFINICIÓN DEL MODELO Y DE LOS HIPERPARÁMETROS A OPTIMIZAR
# ==============================================================================
modelo <- rand_forest(
             mode  = "regression",
             mtry  = tune(),
             trees = tune()
          ) %>%
          set_engine(
            engine     = "ranger",
            max.depth  = tune(),
            importance = "none",
            seed       = 123
          )

# DEFINICIÓN DEL PREPROCESADO
# ==============================================================================
# En este caso no hay preprocesado, por lo que el transformer solo contiene
# la definición de la fórmula y los datos de entrenamiento.
transformer <- recipe(
                  formula = mejor_resp_num_ok ~ .,
                  data    =  X2
               )

# DEFINICIÓN DE LA ESTRATEGIA DE VALIDACIÓN Y CREACIÓN DE PARTICIONES
# ==============================================================================
set.seed(1234)
cv_folds <- vfold_cv(
              data    = X2,
              v       = nrow(X2),
              repeats = 1,
              strata  = mejor_resp_num_ok
            )

# WORKFLOW
# ==============================================================================
workflow_modelado <- workflow() %>%
                     add_recipe(transformer) %>%
                     add_model(modelo)
                     

# GRID DE HIPERPARÁMETROS
# ==============================================================================
hiperpar_grid <- expand_grid(
                  'trees'     = c(50, 100, 500, 1000, 5000),
                  'mtry'      = c(3, 5, 7, ncol(X2)-1),
                  'max.depth' = c(1, 3, 10, 20)
                 )

# EJECUCIÓN DE LA OPTIMIZACIÓN DE HIPERPARÁMETROS
# ==============================================================================

cl3 <- makePSOCKcluster(parallel::detectCores() - 1)
registerDoParallel(cl3)

grid_fit <- tune_grid(
              object    = workflow_modelado,
              resamples = cv_folds,
              metrics   = metric_set(rmse),
              grid      = hiperpar_grid
            )

stopCluster(cl3)
```

```{r}
# Mejores hiperparámetros por validación cruzada
# ==============================================================================
show_best(grid_fit, metric = "rmse", n = 1)
```

### Entrenar el modelo con los mejores hiperparámetros
```{r}
# ENTRENAMIENTO FINAL
# =============================================================================
mejores_hiperpar <- select_best(grid_fit, metric = "rmse")

modelo_final_fit <- finalize_workflow(
                        x = workflow_modelado,
                        parameters = mejores_hiperpar
                    ) %>%
                    fit(
                      data = X2
                    ) %>%
                    extract_fit_parsnip()
```

```{r}
# Error de train del modelo final
# ==============================================================================
predicciones <- modelo_final_fit %>%
                predict(
                  new_data = X2,
                  type     = "numeric"
                )

predicciones <- predicciones %>% 
                bind_cols(X2 %>% dplyr::select(mejor_resp_num_ok))

rmse_train  <- rmse(
                 data     = predicciones,
                 truth    = mejor_resp_num_ok,
                 estimate = .pred,
                 na_rm    = TRUE
              )
rmse_train
```

## Importancia de predictores

Importancia por pureza de nodos

En los modelos anteriores, el argumento importance se deja por defecto como "none". Esto desactiva el cálculo de importancia de predictores para reducir así el tiempo de entrenamiento. Se entrena de nuevo el modelo, con los mejores hiperparámetros encontrados, pero esta vez indicando importance = "impurity". Los modelos ranger calculan la impureza a partir del índice Gini en problemas de clasificación y con la varianza en regresión.

```{r}
# Entrenamiento modelo
modelo <- rand_forest(
             mode  = "regression"
          ) %>%
          set_engine(
            engine     = "ranger",
            importance = "impurity",
            seed       = 123
          )

modelo <- modelo %>% finalize_model(mejores_hiperpar)
modelo <- modelo %>% fit(mejor_resp_num_ok ~., data = X2)

# Importancia
importancia_pred <- modelo$fit$variable.importance %>%
                    enframe(name = "predictor", value = "importancia")

# Gráfico
ggplot(
  data = importancia_pred,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "predictor", title = "Importancia predictores (pureza de nodos)") +
geom_col() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 5))
```
## TOP 15
```{r}
# Filtrar para mantener solo las 15 variables más importantes
importancia_pred_top15 <- importancia_pred %>%
                          arrange(desc(importancia)) %>%
                          top_n(15, importancia)

# Gráfico de las 15 variables más importantes
ggplot(
  data = importancia_pred_top15,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "Predictor", title = "Importancia de los predictores (pureza de nodos)") +
geom_col() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 12))
```

## Importancia por permutación
Se entrena de nuevo el modelo, con los mejores hiperparámetros encontrados, pero esta vez indicando importance = "permutation".
```{r}
# Entrenamiento modelo
modelo <- rand_forest(
             mode  = "regression"
          ) %>%
          set_engine(
            engine     = "ranger",
            importance = "permutation",
            seed       = 123
          )

modelo <- modelo %>% finalize_model(mejores_hiperpar)
modelo <- modelo %>% fit(mejor_resp_num_ok ~., data = X2)

# Importancia
importancia_pred <- modelo$fit$variable.importance %>%
                    enframe(name = "predictor", value = "importancia")

# Gráfico
ggplot(
  data = importancia_pred,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "predictor", title = "Importancia predictores (permutación)") +
geom_col() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 5))
```
## Top 15
```{r}
# Filtrar para mantener solo las 15 variables más importantes
importancia_pred_top15 <- importancia_pred %>%
                          arrange(desc(importancia)) %>%
                          slice_max(order_by = importancia, n = 15)  # Usamos slice_max que es más explícito

# Gráfico de las 15 variables más importantes
ggplot(
  data = importancia_pred_top15,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "Predictor", title = "Importancia de los predictores (permutación)") +
geom_col() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 12))
```

Ambas estrategias identifican Grado_tox, Toxicidad, Linf_1eval, PLR_1C y NLR_1eval,  como los predictores más influyentes, acorde a los datos de entrenamiento.

# Clasificación
```{r}
# Remove all objects from the global environment and the console
rm(list = ls())
cat("\014")
```
## Preparing the data
```{r}
df <- read_excel("df_definitivo-2.xlsx", sheet = "Copia de datos")
rownames(df) = df$id
df$Afectacion_ganglionar = as.numeric(df$Afectacion_ganglionar)
df$Afectacion_metastasica = as.numeric(df$Afectacion_metastasica)
df$Tamaño_tumor = as.numeric(df$Tamaño_tumor)
df$Grado_tox = as.numeric(df$Grado_tox)
df$SII_pre = log(df$SII_pre)
df$SII_1C = log(df$SII_1C)
df$SII_2C = log(df$SII_2C)
df$SII_1eval = log(df$SII_1eval)

variables_inutiles = c("Anciano", "Peso", "Talla", "SG", "SG_cens", "SLP", "SLP_cens", "Tipo_tox", "NLR2C_corte4o5")

df2 = select(df, -all_of(variables_inutiles))
```

## SELECCIÓN DE VARIABLES PARA MEJOR RESPUESTA
```{r SELECCIÓN DE VARIABLES PARA MEJOR RESPUESTA}
X2 = df2[,2:67]
X2$mejor_resp_num_ok <- as.factor(df2$mejor_resp_num_ok)
```

## Modelo sin hiperparámetros
```{r}
# Creación y entrenamiento del modelo
# ==============================================================================
set.seed(123)
modelo_sin_ajustar  <- ranger(
            formula   = mejor_resp_num_ok ~ .,
            data      = X2,
            num.trees = 10,
            seed      = 123
           )

print(modelo_sin_ajustar)
```

```{r}
predict(modelo_sin_ajustar, X2) %>% head
```

## Ealuating the model
```{r}
# Training data
p_train <- predict(modelo_sin_ajustar, X2)

# Evaluation data frame (Training)
eval_train <- data.frame(obs=X2$mejor_resp_num_ok,
                         pred=p_train)
head(eval_train)

predicciones_ <- p_train$predictions

```

```{r}
# Generar predicciones
predicciones <- predict(modelo_sin_ajustar, data = X2)

# Asegúrate de que las predicciones están en el formato adecuado
# Extrae las predicciones de clase si es un problema de clasificación
predicciones_ <- predicciones$predictions

# Crear un marco de datos para evaluación que incluya observaciones y predicciones
eval_train <- data.frame(
  obs = X2$mejor_resp_num_ok,  # las observaciones reales
  pred = as.factor(predicciones_)  # asegúrate de convertir las predicciones a factor
)

# Matriz de confusión usando yardstick
mat_confusion <- conf_mat(data = eval_train, truth = obs, estimate = pred)
mat_confusion

```

## Mejora de los hiperparámetros
```{r}
# DEFINICIÓN DEL MODELO Y DE LOS HIPERPARÁMETROS A OPTIMIZAR
# ==============================================================================
modelo <- rand_forest(
             mode  = "classification",
             mtry  = tune(),
             trees = tune()
          ) %>%
          set_engine(
            engine     = "ranger",
            max.depth  = tune(),
            importance = "none",
            seed       = 123
          )

# DEFINICIÓN DEL PREPROCESADO
# ==============================================================================
# En este caso no hay preprocesado, por lo que el transformer solo contiene
# la definición de la fórmula y los datos de entrenamiento.
transformer <- recipe(
                  formula = mejor_resp_num_ok ~ .,
                  data    =  X2
               )

# DEFINICIÓN DE LA ESTRATEGIA DE VALIDACIÓN Y CREACIÓN DE PARTICIONES
# ==============================================================================
set.seed(1234)
cv_folds <- vfold_cv(
              data    = X2,
              v       = nrow(X2),
              repeats = 1,
              strata  = mejor_resp_num_ok
            )

# WORKFLOW
# ==============================================================================
workflow_modelado <- workflow() %>%
                     add_recipe(transformer) %>%
                     add_model(modelo)
                     

# GRID DE HIPERPARÁMETROS
# ==============================================================================
hiperpar_grid <- expand_grid(
                  'trees'     = c(50, 100, 500, 1000, 5000),
                  'mtry'      = c(3, 5, 7, ncol(X2)-1),
                  'max.depth' = c(1, 3, 10, 20)
                 )

# EJECUCIÓN DE LA OPTIMIZACIÓN DE HIPERPARÁMETROS
# ==============================================================================
cl <- makePSOCKcluster(parallel::detectCores() - 1)
registerDoParallel(cl)

grid_fit <- tune_grid(
              object    = workflow_modelado,
              resamples = cv_folds,
              metrics   = metric_set(accuracy),
              grid      = hiperpar_grid
            )

stopCluster(cl)
```

```{r}
# Mejores hiperparámetros por validación cruzada
# ==============================================================================
show_best(grid_fit, metric = "accuracy", n = 1)
```

```{r}
# ENTRENAMIENTO FINAL
# =============================================================================
mejores_hiperpar <- select_best(grid_fit, metric = "accuracy")

modelo_final_fit <- finalize_workflow(
                        x = workflow_modelado,
                        parameters = mejores_hiperpar
                    ) %>%
                    fit(
                      data = X2
                    ) %>%
                    extract_fit_parsnip()
```

```{r}
# Error de train del modelo final
# ==============================================================================
predicciones <- modelo_final_fit %>%
                predict(new_data = X2)

predicciones <- predicciones %>% 
                bind_cols(X2 %>% dplyr::select(mejor_resp_num_ok))

accuracy_test  <- accuracy(
                     data     = predicciones,
                     truth    = mejor_resp_num_ok,
                     estimate = .pred_class,
                     na_rm    = TRUE
                  )
accuracy_test
```

```{r}
mat_confusion <- predicciones %>%
                 conf_mat(
                   truth     = mejor_resp_num_ok,
                   estimate  = .pred_class
                 )
mat_confusion
```

## Predicción de probabilidades
La mayoría de implementaciones de Random Forest, entre ellas la de ranger, permiten predecir probabilidades cuando se trata de problemas de clasificación. Es importante entender cómo se calculan estos valores para interpretarlos y utilizarlos correctamente.

En el ejemplo anterior, al aplicar predict() se devuelve Si (ventas elevadas) o No (ventas bajas) para cada observación de test. Sin embargo, no se dispone de ningún tipo de información sobre la seguridad con la que el modelo realiza esta asignación. Con predict(type="prob"), en lugar de una clasificación, se obtiene la probabilidad con la que el modelo considera que cada observación puede pertenecer a cada una de las clases.

```{r}
# Predicción de probabilidades
# ==============================================================================
predicciones <- modelo_final_fit %>%
                predict(new_data = X2, type = "prob")
head(predicciones, 4)
```

El resultado de predict(type="prob") es un dataframe con una fila por observación y tantas columnas como clases tenga la variable respuesta. El valor de la primera columna se corresponde con la probabilidad, acorde al modelo, de que la observación pertenezca a la clase No, y así sucesivamente. El valor de probabilidad mostrado para cada predicción se corresponde con la fracción de observaciones de cada clase en los nodos terminales a los que ha llegado la observación predicha en el conjunto de los árboles.

Por defecto, predict() asigna cada nueva observación a la clase con mayor probabilidad (en caso de empate se asigna de forma aleatoria). Sin embargo, este no tiene por qué ser el comportamiento deseado en todos los casos.

## Importancia de predictores

Importancia por pureza de nodos

En los modelos anteriores, el argumento importance se deja por defecto como "none". Esto desactiva el cálculo de importancia de predictores para reducir así el tiempo de entrenamiento. Se entrena de nuevo el modelo, con los mejores hiperparámetros encontrados, pero esta vez indicando importance = "impurity". Los modelos ranger calculan la impureza a partir del índice Gini en problemas de clasificación y con la varianza en regresión.

```{r}
# Entrenamiento modelo
modelo <- rand_forest(
             mode  = "classification"
          ) %>%
          set_engine(
            engine     = "ranger",
            importance = "impurity",
            seed       = 123
          )

modelo <- modelo %>% finalize_model(mejores_hiperpar)
modelo <- modelo %>% fit(mejor_resp_num_ok ~., data = X2)

# Importancia
importancia_pred <- modelo$fit$variable.importance %>%
                    enframe(name = "predictor", value = "importancia")

# Gráfico
ggplot(
  data = importancia_pred,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "predictor", title = "Importancia predictores (pureza de nodos)") +
geom_col() +
scale_fill_viridis_c() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 5))
```
## TOP 15

```{r}
# Filtrar para mantener solo las 15 variables más importantes
importancia_pred_top15 <- importancia_pred %>%
                          arrange(desc(importancia)) %>%
                          top_n(15, importancia)

# Gráfico de las 15 variables más importantes
ggplot(
  data = importancia_pred_top15,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "Predictor", title = "Importancia de los predictores (pureza de nodos)") +
geom_col() +
scale_fill_viridis_c() +  # Usa un gradiente de color para representar la importancia
coord_flip() +  # Invierte los ejes para mejor visualización de las etiquetas
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 12))  # Ajusta el tamaño del texto para mejor legibilidad

```

## Importancia por permutación
Se entrena de nuevo el modelo, con los mejores hiperparámetros encontrados, pero esta vez indicando importance = "permutation".
```{r}
# Entrenamiento modelo
modelo <- rand_forest(
             mode  = "classification"
          ) %>%
          set_engine(
            engine     = "ranger",
            importance = "permutation",
            seed       = 123
          )

modelo <- modelo %>% finalize_model(mejores_hiperpar)
modelo <- modelo %>% fit(mejor_resp_num_ok ~., data = X2)

# Importancia
importancia_pred <- modelo$fit$variable.importance %>%
                    enframe(name = "predictor", value = "importancia")

# Gráfico
ggplot(
  data = importancia_pred,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "predictor", title = "Importancia predictores (permutación)") +
geom_col() +
scale_fill_viridis_c() +
coord_flip() +
theme_bw() +
theme(legend.position = "none", axis.text = element_text(size = 5))
```
## TOP 15

```{r}
# Filtrar para mantener solo las 15 variables más importantes
importancia_pred_top15 <- importancia_pred %>%
                          arrange(desc(importancia)) %>%
                          top_n(15, importancia)

# Gráfico de las 15 variables más importantes
ggplot(
  data = importancia_pred_top15,
  aes(x    = reorder(predictor, importancia),
      y    = importancia,
      fill = importancia)
) +
labs(x = "Predictor", title = "Importancia de los predictores (permutación)") +
geom_col() +
scale_fill_viridis_c() +  # Utiliza una escala de color para representar la importancia
coord_flip() +  # Invierte los ejes para una mejor visualización de los nombres de los predictores
theme_bw() +  # Utiliza un tema blanco y negro para el gráfico
theme(legend.position = "none", axis.text = element_text(size = 12))  # Ajusta el tamaño del texto para mejorar la legibilidad
```


Ambas estrategias identifican SII_2C, LDH, SII_1C, NLR_1C, y SII_2C,  como los predictores más influyentes, acorde a los datos de entrenamiento.